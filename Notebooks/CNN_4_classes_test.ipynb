{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36452001",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6e9389ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All imports done\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report,accuracy_score\n",
    "from sklearn import svm\n",
    "from skimage.io import imread, imshow\n",
    "from keras.preprocessing import image\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, MaxPool1D, Flatten, InputLayer, BatchNormalization\n",
    "from keras.layers import Dense, Dropout, Conv2D, MaxPool2D, Activation, MaxPooling2D\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import os \n",
    "\n",
    "print(\"All imports done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed25202",
   "metadata": {},
   "source": [
    "## Data preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "913e2768",
   "metadata": {},
   "outputs": [],
   "source": [
    "basedir = './dataset'\n",
    "images_dir = os.path.join(basedir,'image')\n",
    "labels_filename = 'label.csv'\n",
    "\n",
    "def categorical_labelling(): \n",
    "    labels_file = open(os.path.join(basedir, labels_filename), 'r')\n",
    "    lines = labels_file.readlines()\n",
    "    tumor_labels = {line.split(',')[0] : (line.split(',')[1].strip()) for line in lines[1:]}\n",
    "\n",
    "    for i in tumor_labels: \n",
    "        if tumor_labels[i] == 'no_tumor': \n",
    "            tumor_labels[i] = 0\n",
    "        elif tumor_labels[i] == \"meningioma_tumor\":\n",
    "            tumor_labels[i] = 1\n",
    "        elif tumor_labels[i] == \"glioma_tumor\":\n",
    "            tumor_labels[i] = 2\n",
    "        elif tumor_labels[i] == \"pituitary_tumor\":\n",
    "            tumor_labels[i] = 3\n",
    "    return(tumor_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a12ba732",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features():\n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "    \n",
    "    labels = categorical_labelling()\n",
    "\n",
    "    image_paths = [os.path.join(images_dir, l) for l in os.listdir(images_dir)]\n",
    "    if os.path.isdir(images_dir):\n",
    "        all_features = []\n",
    "        all_labels = []\n",
    "        for img_path in image_paths:\n",
    "            filename = img_path.split('/')[-1]\n",
    "            features = imread(img_path, as_gray=True)\n",
    "            features.shape, features\n",
    "            all_features.append(features)\n",
    "            all_labels.append(labels[filename])\n",
    "    np_features = np.array(all_features)\n",
    "    np_labels = np.array(all_labels)\n",
    "    \n",
    "    np_features =np_features.reshape(-1,512, 512,1)\n",
    "#     np_labels = np_labels.reshape(-1,512, 512,1)\n",
    "    \n",
    "    \n",
    "    return np_features, np_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14d17148",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(): \n",
    "\n",
    "    X, Y = extract_features()\n",
    "\n",
    "    tr_X = X[:2400]\n",
    "    tr_Y = Y[:2400]\n",
    "    te_X = X[2400:]\n",
    "    te_Y = Y[2400:]\n",
    "    \n",
    "    return tr_X, tr_Y, te_X, te_Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2cdb495",
   "metadata": {},
   "source": [
    "## Testing data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "caf07355",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Preparing testing dataset\n",
    "\n",
    "testdir = './test'\n",
    "test_images_dir = os.path.join(testdir,'image')\n",
    "test_labels_filename = 'label.csv'\n",
    "\n",
    "def categorical_labelling_testset():\n",
    "    labels_file = open(os.path.join(testdir, test_labels_filename), 'r')\n",
    "    lines = labels_file.readlines()\n",
    "    tumor_labels = {line.split(',')[0] : (line.split(',')[1].strip()) for line in lines[1:]}\n",
    "\n",
    "    for i in tumor_labels: \n",
    "        if tumor_labels[i] == 'no_tumor': \n",
    "            tumor_labels[i] = 0\n",
    "        elif tumor_labels[i] == \"meningioma_tumor\":\n",
    "            tumor_labels[i] = 1\n",
    "        elif tumor_labels[i] == \"glioma_tumor\":\n",
    "            tumor_labels[i] = 2\n",
    "        elif tumor_labels[i] == \"pituitary_tumor\":\n",
    "            tumor_labels[i] = 3\n",
    "    return(tumor_labels)\n",
    "\n",
    "def extract_features_with_conv_testset():\n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "    \n",
    "    labels = categorical_labelling_testset()\n",
    "\n",
    "    image_paths = [os.path.join(test_images_dir, l) for l in os.listdir(test_images_dir)]\n",
    "    if os.path.isdir(images_dir):\n",
    "        all_features = []\n",
    "        all_labels = []\n",
    "        for img_path in image_paths:\n",
    "            filename = img_path.split('/')[-1]\n",
    "            features = imread(img_path, as_gray=True)\n",
    "            all_features.append(features)\n",
    "            all_labels.append(labels[filename])\n",
    "    np_features = np.array(all_features)\n",
    "    np_labels = np.array(all_labels)\n",
    "    \n",
    "    np_features = np_features.reshape(-1,512, 512,1)\n",
    "#     np_labels = np_labels.reshape(-1,512, 512,1)\n",
    "    \n",
    "    return np_features, np_labels\n",
    "\n",
    "def get_test_data(): \n",
    "\n",
    "    X, Y = extract_features_with_conv_testset()\n",
    "    \n",
    "    te_X = X\n",
    "    te_Y = Y\n",
    "    \n",
    "    return te_X, te_Y\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faea5f6e",
   "metadata": {},
   "source": [
    "## Using One-encoding to avoid shape errors on the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22a213f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_train, y_train, x_test, y_test = get_data()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a448d5c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_14 (Conv2D)           (None, 510, 510, 32)      320       \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 510, 510, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 255, 255, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 253, 253, 32)      9248      \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 253, 253, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 126, 126, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 124, 124, 64)      18496     \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 124, 124, 64)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 62, 62, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 246016)            0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 64)                15745088  \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 4)                 260       \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 15,773,412\n",
      "Trainable params: 15,773,412\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_CNN_plus = Sequential()\n",
    "model_CNN_plus.add(Conv2D(32, (3, 3), input_shape=(512, 512, 1)))\n",
    "model_CNN_plus.add(Activation('relu'))\n",
    "model_CNN_plus.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model_CNN_plus.add(Conv2D(32, (3, 3)))\n",
    "model_CNN_plus.add(Activation('relu'))\n",
    "model_CNN_plus.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model_CNN_plus.add(Conv2D(64, (3, 3)))\n",
    "model_CNN_plus.add(Activation('relu'))\n",
    "model_CNN_plus.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model_CNN_plus.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "model_CNN_plus.add(Dense(64))\n",
    "model_CNN_plus.add(Activation('relu'))\n",
    "model_CNN_plus.add(Dropout(0.5))\n",
    "model_CNN_plus.add(Dense(4))\n",
    "model_CNN_plus.add(Activation('sigmoid'))\n",
    "\n",
    "model_CNN_plus.summary()\n",
    "\n",
    "model_CNN_plus.compile(loss='binary_crossentropy',\n",
    "              optimizer=Adam(lr=0.0001),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee979ece",
   "metadata": {},
   "source": [
    "### The difference is made here: the label inputs (train and test) are one-hot encoded\n",
    "\n",
    "Note: fitting this model takes more than 10hours to run on a CPU. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "60f4921e",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(lr = 10e-5)\n",
    "\n",
    "model_CNN_plus.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer=\"adam\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "45cc9466",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes=4)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0bb79ff6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2400, 512, 512, 1)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "09f78f38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2400 samples, validate on 600 samples\n",
      "Epoch 1/20\n",
      "2400/2400 [==============================] - 1160s 483ms/step - loss: 0.5577 - accuracy: 0.7395 - val_loss: 0.4927 - val_accuracy: 0.7571\n",
      "Epoch 2/20\n",
      "2400/2400 [==============================] - 1219s 508ms/step - loss: 0.4853 - accuracy: 0.7716 - val_loss: 0.4290 - val_accuracy: 0.8037\n",
      "Epoch 3/20\n",
      "2400/2400 [==============================] - 1282s 534ms/step - loss: 0.4223 - accuracy: 0.8018 - val_loss: 0.3791 - val_accuracy: 0.8525\n",
      "Epoch 4/20\n",
      "2400/2400 [==============================] - 1277s 532ms/step - loss: 0.3773 - accuracy: 0.8326 - val_loss: 0.3397 - val_accuracy: 0.8671\n",
      "Epoch 5/20\n",
      "2400/2400 [==============================] - 1342s 559ms/step - loss: 0.3340 - accuracy: 0.8514 - val_loss: 0.3274 - val_accuracy: 0.8729\n",
      "Epoch 6/20\n",
      "2400/2400 [==============================] - 1347s 561ms/step - loss: 0.3115 - accuracy: 0.8652 - val_loss: 0.2982 - val_accuracy: 0.8804\n",
      "Epoch 7/20\n",
      "2400/2400 [==============================] - 1397s 582ms/step - loss: 0.2733 - accuracy: 0.8857 - val_loss: 0.2667 - val_accuracy: 0.8983\n",
      "Epoch 8/20\n",
      "2400/2400 [==============================] - 1394s 581ms/step - loss: 0.2483 - accuracy: 0.8976 - val_loss: 0.2568 - val_accuracy: 0.8983\n",
      "Epoch 9/20\n",
      "2400/2400 [==============================] - 1407s 586ms/step - loss: 0.2315 - accuracy: 0.9080 - val_loss: 0.2463 - val_accuracy: 0.9054\n",
      "Epoch 10/20\n",
      "2400/2400 [==============================] - 1381s 575ms/step - loss: 0.2055 - accuracy: 0.9192 - val_loss: 0.2373 - val_accuracy: 0.9062\n",
      "Epoch 11/20\n",
      "2400/2400 [==============================] - 1385s 577ms/step - loss: 0.1941 - accuracy: 0.9224 - val_loss: 0.2375 - val_accuracy: 0.9029\n",
      "Epoch 12/20\n",
      "2400/2400 [==============================] - 1401s 584ms/step - loss: 0.1725 - accuracy: 0.9311 - val_loss: 0.2242 - val_accuracy: 0.9179\n",
      "Epoch 13/20\n",
      "2400/2400 [==============================] - 1433s 597ms/step - loss: 0.1607 - accuracy: 0.9402 - val_loss: 0.2115 - val_accuracy: 0.9150\n",
      "Epoch 14/20\n",
      "2400/2400 [==============================] - 1432s 597ms/step - loss: 0.1404 - accuracy: 0.9470 - val_loss: 0.2099 - val_accuracy: 0.9192\n",
      "Epoch 15/20\n",
      "2400/2400 [==============================] - 1427s 595ms/step - loss: 0.1293 - accuracy: 0.9527 - val_loss: 0.2094 - val_accuracy: 0.9212\n",
      "Epoch 16/20\n",
      "2400/2400 [==============================] - 1407s 586ms/step - loss: 0.1216 - accuracy: 0.9548 - val_loss: 0.2128 - val_accuracy: 0.9179\n",
      "Epoch 17/20\n",
      "2400/2400 [==============================] - 1395s 581ms/step - loss: 0.1130 - accuracy: 0.9570 - val_loss: 0.2103 - val_accuracy: 0.9187\n",
      "Epoch 18/20\n",
      "2400/2400 [==============================] - 1431s 596ms/step - loss: 0.0975 - accuracy: 0.9663 - val_loss: 0.2089 - val_accuracy: 0.9204\n",
      "Epoch 19/20\n",
      "2400/2400 [==============================] - 1400s 583ms/step - loss: 0.0980 - accuracy: 0.9643 - val_loss: 0.2042 - val_accuracy: 0.9221\n",
      "Epoch 20/20\n",
      "2400/2400 [==============================] - 1411s 588ms/step - loss: 0.0905 - accuracy: 0.9691 - val_loss: 0.2074 - val_accuracy: 0.9233\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f8eab69c490>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model_CNN_plus.fit(x_train, tf.one_hot(y_train, 4) ,steps_per_epoch = 30, epochs = 15 ,validation_data=(x_test, tf.one_hot(y_test, 4)), validation_steps = 10)\n",
    "model_CNN_plus.fit(x_train, y_train,batch_size = 64, epochs = 20 ,validation_data=(x_test, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c9bbeb",
   "metadata": {},
   "source": [
    "## Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "026ed837",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_CNN_plus.save('CNN_Model_Cat_one_hot')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e7fd1c",
   "metadata": {},
   "source": [
    "## Loading One-Hot Encoded model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "38907e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('CNN_Model_Cat_one_hot')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8781432",
   "metadata": {},
   "source": [
    "## Evaluating using testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "630a1188",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X, y = extract_features_with_conv_testset()\n",
    "\n",
    "\n",
    "x_TEST, y_TEST = get_test_data()\n",
    "y_TEST = tf.keras.utils.to_categorical(y_TEST, num_classes=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5db079e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 4)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_TEST.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1042d058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 11s 57ms/step\n",
      "test loss, test acc: [0.18194288969039918, 0.9300000071525574]\n"
     ]
    }
   ],
   "source": [
    "result_one_hot = model_CNN_plus.evaluate(x_TEST, y_TEST)\n",
    "\n",
    "print(\"test loss, test acc:\", result_one_hot)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
