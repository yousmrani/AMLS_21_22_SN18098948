{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36452001",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e9389ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All imports done\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report,accuracy_score\n",
    "from skimage.io import imread, imshow\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPool2D, Flatten, InputLayer, BatchNormalization, Dense, Dropout, MaxPooling2D, Activation\n",
    "from keras.optimizers import Adam\n",
    "import os \n",
    "\n",
    "print(\"All imports done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed25202",
   "metadata": {},
   "source": [
    "## Data preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "913e2768",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we set the path to find the images\n",
    "basedir = './dataset'\n",
    "images_dir = os.path.join(basedir,'image')\n",
    "labels_filename = 'label.csv'\n",
    "\n",
    "# This function will loop through the csv file containing the labels and create a dictionnary containing the \n",
    "# name of the image as a key and the associate label as a value\n",
    "def categorical_labelling(): \n",
    "    labels_file = open(os.path.join(basedir, labels_filename), 'r')\n",
    "    lines = labels_file.readlines()\n",
    "    tumor_labels = {line.split(',')[0] : (line.split(',')[1].strip()) for line in lines[1:]}\n",
    "\n",
    "    for i in tumor_labels: \n",
    "        if tumor_labels[i] == 'no_tumor': \n",
    "            tumor_labels[i] = 0\n",
    "        elif tumor_labels[i] == \"meningioma_tumor\":\n",
    "            tumor_labels[i] = 1\n",
    "        elif tumor_labels[i] == \"glioma_tumor\":\n",
    "            tumor_labels[i] = 2\n",
    "        elif tumor_labels[i] == \"pituitary_tumor\":\n",
    "            tumor_labels[i] = 3\n",
    "    return(tumor_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a12ba732",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function will loop through the images and using the name of the image and the dictionnary set in the previous \n",
    "#function, will return two array containing the features and the label\n",
    "def extract_features():\n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "    \n",
    "    labels = categorical_labelling()\n",
    "\n",
    "    image_paths = [os.path.join(images_dir, l) for l in os.listdir(images_dir)]\n",
    "    if os.path.isdir(images_dir):\n",
    "        all_features = []\n",
    "        all_labels = []\n",
    "        for img_path in image_paths:\n",
    "            filename = img_path.split('/')[-1]\n",
    "            features = imread(img_path, as_gray=True)\n",
    "            features.shape, features\n",
    "            all_features.append(features)\n",
    "            all_labels.append(labels[filename])\n",
    "    np_features = np.array(all_features)\n",
    "    np_labels = np.array(all_labels)\n",
    "    \n",
    "    np_features =np_features.reshape(-1,512, 512,1) # array of features needs to be changed to correspond to the  \n",
    "                                                    # input shape of CNN\n",
    "\n",
    "    \n",
    "    \n",
    "    return np_features, np_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14d17148",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is used to separate the dataset into a training and testing set with proportion 80% - 20% and returns\n",
    "# the associated training features, training labels, validation features and validation labels\n",
    "\n",
    "def get_data(): \n",
    "\n",
    "    X, Y = extract_features()\n",
    "\n",
    "    tr_X = X[:2400]\n",
    "    tr_Y = Y[:2400]\n",
    "    te_X = X[2400:]\n",
    "    te_Y = Y[2400:]\n",
    "    \n",
    "    return tr_X, tr_Y, te_X, te_Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2cdb495",
   "metadata": {},
   "source": [
    "## Testing data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "caf07355",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Preparing testing dataset by modifying the function used earlier\n",
    "\n",
    "testdir = './test'\n",
    "test_images_dir = os.path.join(testdir,'image')\n",
    "test_labels_filename = 'label.csv'\n",
    "\n",
    "def categorical_labelling_testset():\n",
    "    labels_file = open(os.path.join(testdir, test_labels_filename), 'r')\n",
    "    lines = labels_file.readlines()\n",
    "    tumor_labels = {line.split(',')[0] : (line.split(',')[1].strip()) for line in lines[1:]}\n",
    "\n",
    "    for i in tumor_labels: \n",
    "        if tumor_labels[i] == 'no_tumor': \n",
    "            tumor_labels[i] = 0\n",
    "        elif tumor_labels[i] == \"meningioma_tumor\":\n",
    "            tumor_labels[i] = 1\n",
    "        elif tumor_labels[i] == \"glioma_tumor\":\n",
    "            tumor_labels[i] = 2\n",
    "        elif tumor_labels[i] == \"pituitary_tumor\":\n",
    "            tumor_labels[i] = 3\n",
    "    return(tumor_labels)\n",
    "\n",
    "def extract_features_with_conv_testset():\n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "    \n",
    "    labels = categorical_labelling_testset()\n",
    "\n",
    "    image_paths = [os.path.join(test_images_dir, l) for l in os.listdir(test_images_dir)]\n",
    "    if os.path.isdir(images_dir):\n",
    "        all_features = []\n",
    "        all_labels = []\n",
    "        for img_path in image_paths:\n",
    "            filename = img_path.split('/')[-1]\n",
    "            features = imread(img_path, as_gray=True)\n",
    "            all_features.append(features)\n",
    "            all_labels.append(labels[filename])\n",
    "    np_features = np.array(all_features)\n",
    "    np_labels = np.array(all_labels)\n",
    "    \n",
    "    np_features = np_features.reshape(-1,512, 512,1)\n",
    "    \n",
    "    return np_features, np_labels\n",
    "\n",
    "def get_test_data(): \n",
    "\n",
    "    X, Y = extract_features_with_conv_testset()\n",
    "    \n",
    "    te_X = X\n",
    "    te_Y = Y\n",
    "    \n",
    "    return te_X, te_Y\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faea5f6e",
   "metadata": {},
   "source": [
    "## Create CNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22a213f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assign features and labels to the corresponding variables\n",
    "x_train, y_train, x_test, y_test = get_data()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a448d5c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_14 (Conv2D)           (None, 510, 510, 32)      320       \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 510, 510, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 255, 255, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 253, 253, 32)      9248      \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 253, 253, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 126, 126, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 124, 124, 64)      18496     \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 124, 124, 64)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 62, 62, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 246016)            0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 64)                15745088  \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 4)                 260       \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 15,773,412\n",
      "Trainable params: 15,773,412\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# The model is set to be sequential()\n",
    "model_CNN_plus = Sequential()\n",
    "model_CNN_plus.add(Conv2D(32, (3, 3), input_shape=(512, 512, 1))) #Setting the first convolution layer and giving the input shape\n",
    "model_CNN_plus.add(Activation('relu')) # Selecting the activation function linked to the conv layer\n",
    "model_CNN_plus.add(MaxPooling2D(pool_size=(2, 2))) #Setting the maxpooling layer \n",
    "\n",
    "# We add another set of Conv, Activation and MaxPooling to make the CNN stronger. \n",
    "model_CNN_plus.add(Conv2D(32, (3, 3)))\n",
    "model_CNN_plus.add(Activation('relu'))\n",
    "model_CNN_plus.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# We add another set of Conv, Activation and MaxPooling to make the CNN stronger. \n",
    "model_CNN_plus.add(Conv2D(64, (3, 3)))\n",
    "model_CNN_plus.add(Activation('relu'))\n",
    "model_CNN_plus.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model_CNN_plus.add(Flatten())  # This line is used to convert our model from 3d to 1d\n",
    "\n",
    "#Add the fully connected layer\n",
    "model_CNN_plus.add(Dense(64))\n",
    "model_CNN_plus.add(Activation('relu'))\n",
    "model_CNN_plus.add(Dropout(0.5)) #We use dropout to avoid overfitting\n",
    "model_CNN_plus.add(Dense(4)) #As we have 4 outputs (3 types of tumour and 1 no tumour), we put 4 categories\n",
    "model_CNN_plus.add(Activation('sigmoid'))\n",
    "\n",
    "#Shows the construction of our model (interesting for troubleshooting )\n",
    "model_CNN_plus.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee979ece",
   "metadata": {},
   "source": [
    "### Compilation of the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "60f4921e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer = Adam(lr = 10e-5)\n",
    "# For compilation we use categorical cross entropy as we have 4 categories. We also use accuracy as metrics and adam optimsier \n",
    "model_CNN_plus.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer=\"adam\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d55d94ca",
   "metadata": {},
   "source": [
    "### One-hot-encoding of inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "45cc9466",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As we have multiple categories, we need to use one-hot-encoding on the labels in order to fit our model use the extracted label and features\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes=4)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0bb79ff6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2400, 512, 512, 1)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The shape of our feature vector is: \n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa649fe",
   "metadata": {},
   "source": [
    "### Training of the model\n",
    "Note: fitting this model takes more than 10hours to run on a CPU. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "09f78f38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2400 samples, validate on 600 samples\n",
      "Epoch 1/20\n",
      "2400/2400 [==============================] - 1160s 483ms/step - loss: 0.5577 - accuracy: 0.7395 - val_loss: 0.4927 - val_accuracy: 0.7571\n",
      "Epoch 2/20\n",
      "2400/2400 [==============================] - 1219s 508ms/step - loss: 0.4853 - accuracy: 0.7716 - val_loss: 0.4290 - val_accuracy: 0.8037\n",
      "Epoch 3/20\n",
      "2400/2400 [==============================] - 1282s 534ms/step - loss: 0.4223 - accuracy: 0.8018 - val_loss: 0.3791 - val_accuracy: 0.8525\n",
      "Epoch 4/20\n",
      "2400/2400 [==============================] - 1277s 532ms/step - loss: 0.3773 - accuracy: 0.8326 - val_loss: 0.3397 - val_accuracy: 0.8671\n",
      "Epoch 5/20\n",
      "2400/2400 [==============================] - 1342s 559ms/step - loss: 0.3340 - accuracy: 0.8514 - val_loss: 0.3274 - val_accuracy: 0.8729\n",
      "Epoch 6/20\n",
      "2400/2400 [==============================] - 1347s 561ms/step - loss: 0.3115 - accuracy: 0.8652 - val_loss: 0.2982 - val_accuracy: 0.8804\n",
      "Epoch 7/20\n",
      "2400/2400 [==============================] - 1397s 582ms/step - loss: 0.2733 - accuracy: 0.8857 - val_loss: 0.2667 - val_accuracy: 0.8983\n",
      "Epoch 8/20\n",
      "2400/2400 [==============================] - 1394s 581ms/step - loss: 0.2483 - accuracy: 0.8976 - val_loss: 0.2568 - val_accuracy: 0.8983\n",
      "Epoch 9/20\n",
      "2400/2400 [==============================] - 1407s 586ms/step - loss: 0.2315 - accuracy: 0.9080 - val_loss: 0.2463 - val_accuracy: 0.9054\n",
      "Epoch 10/20\n",
      "2400/2400 [==============================] - 1381s 575ms/step - loss: 0.2055 - accuracy: 0.9192 - val_loss: 0.2373 - val_accuracy: 0.9062\n",
      "Epoch 11/20\n",
      "2400/2400 [==============================] - 1385s 577ms/step - loss: 0.1941 - accuracy: 0.9224 - val_loss: 0.2375 - val_accuracy: 0.9029\n",
      "Epoch 12/20\n",
      "2400/2400 [==============================] - 1401s 584ms/step - loss: 0.1725 - accuracy: 0.9311 - val_loss: 0.2242 - val_accuracy: 0.9179\n",
      "Epoch 13/20\n",
      "2400/2400 [==============================] - 1433s 597ms/step - loss: 0.1607 - accuracy: 0.9402 - val_loss: 0.2115 - val_accuracy: 0.9150\n",
      "Epoch 14/20\n",
      "2400/2400 [==============================] - 1432s 597ms/step - loss: 0.1404 - accuracy: 0.9470 - val_loss: 0.2099 - val_accuracy: 0.9192\n",
      "Epoch 15/20\n",
      "2400/2400 [==============================] - 1427s 595ms/step - loss: 0.1293 - accuracy: 0.9527 - val_loss: 0.2094 - val_accuracy: 0.9212\n",
      "Epoch 16/20\n",
      "2400/2400 [==============================] - 1407s 586ms/step - loss: 0.1216 - accuracy: 0.9548 - val_loss: 0.2128 - val_accuracy: 0.9179\n",
      "Epoch 17/20\n",
      "2400/2400 [==============================] - 1395s 581ms/step - loss: 0.1130 - accuracy: 0.9570 - val_loss: 0.2103 - val_accuracy: 0.9187\n",
      "Epoch 18/20\n",
      "2400/2400 [==============================] - 1431s 596ms/step - loss: 0.0975 - accuracy: 0.9663 - val_loss: 0.2089 - val_accuracy: 0.9204\n",
      "Epoch 19/20\n",
      "2400/2400 [==============================] - 1400s 583ms/step - loss: 0.0980 - accuracy: 0.9643 - val_loss: 0.2042 - val_accuracy: 0.9221\n",
      "Epoch 20/20\n",
      "2400/2400 [==============================] - 1411s 588ms/step - loss: 0.0905 - accuracy: 0.9691 - val_loss: 0.2074 - val_accuracy: 0.9233\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f8eab69c490>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training is started here using the x_train and y_train values and validated on x_test and y_test (validation variables)\n",
    "model_CNN_plus.fit(x_train, y_train,batch_size = 64, epochs = 20 ,validation_data=(x_test, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c9bbeb",
   "metadata": {},
   "source": [
    "## Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "026ed837",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model takes 10 hours to run...better to save it\n",
    "model_CNN_plus.save('CNN_Model_Cat_one_hot')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e7fd1c",
   "metadata": {},
   "source": [
    "## Loading One-Hot Encoded model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38907e97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-05 12:41:53.609804: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-01-05 12:41:53.610120: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 8. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "# Useful if model is saved before\n",
    "model = tf.keras.models.load_model('CNN_Model_Cat_one_hot')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8781432",
   "metadata": {},
   "source": [
    "## Evaluating using testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "630a1188",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We use the functions defined earlier to assign the testing values\n",
    "x_TEST, y_TEST = get_test_data()\n",
    "y_TEST = tf.keras.utils.to_categorical(y_TEST, num_classes=4)\n",
    "\n",
    "y_TEST.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1042d058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/1 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 7s 35ms/sample - loss: 0.1610 - accuracy: 0.9300\n",
      "test loss, test acc: [0.18194288969039918, 0.93]\n"
     ]
    }
   ],
   "source": [
    "result_one_hot = model.evaluate(x_TEST, y_TEST)\n",
    "\n",
    "print(\"test loss, test acc:\", result_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "525c3f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use the model on testing set\n",
    "pred = model.predict_classes(x_TEST, verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f7c953cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 1 1 0 1 1 1 1 0 1 2 0 1 0 1 1 3 2 0 2 1 1 1 0 1 1 0 3 1 1 0 3 1 3 2\n",
      " 2 1 2 0 2 3 2 0 1 3 0 3 1 1 2 3 3 1 2 0 3 3 2 3 3 1 2 3 3 1 0 3 2 1 1 3 1\n",
      " 3 2 3 2 3 0 2 1 3 3 0 1 3 1 0 1 2 2 2 0 3 2 1 1 1 3 0 3 0 1 3 2 1 0 1 3 1\n",
      " 1 0 3 2 3 2 2 0 3 2 3 0 2 1 0 3 2 3 3 1 3 1 1 1 0 1 0 1 1 1 2 0 1 0 2 3 2\n",
      " 1 0 1 1 3 3 0 0 2 3 0 1 3 3 3 2 1 2 0 1 2 1 2 0 0 3 3 1 2 2 1 1 1 1 3 0 0\n",
      " 2 1 1 2 2 3 2 1 3 2 3 1 1 3 3]\n"
     ]
    }
   ],
   "source": [
    "rounded_testing_labels = np.argmax(y_TEST, axis = 1) #We need to decode the one-hot-encoded output before observing the values\n",
    "print(rounded_testing_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d2899276",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "       no tumour       0.88      0.81      0.85        37\n",
      "meningioma_tumor       0.85      0.82      0.84        68\n",
      "    glioma_tumor       0.88      0.86      0.87        43\n",
      " pituitary_tumor       0.90      1.00      0.95        52\n",
      "\n",
      "        accuracy                           0.88       200\n",
      "       macro avg       0.88      0.87      0.87       200\n",
      "    weighted avg       0.87      0.88      0.87       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "c_report_testing = classification_report(rounded_testing_labels, pred, target_names = [\"no tumour\", \"meningioma_tumor\", \"glioma_tumor\", \"pituitary_tumor\"])\n",
    "print(c_report_testing)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
